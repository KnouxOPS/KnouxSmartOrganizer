/**
 * Knoux SmartOrganizer Desktop - Offline AI Manager
 * Manages local AI models and provides system integration
 */

const { app, ipcMain, dialog, shell } = require("electron");
const fs = require("fs").promises;
const path = require("path");
const os = require("os");
const { spawn, exec } = require("child_process");
const EventEmitter = require("events");

class OfflineAIManager extends EventEmitter {
  constructor() {
    super();
    this.modelsPath = path.join(app.getPath("userData"), "ai-models");
    this.configPath = path.join(app.getPath("userData"), "ai-config.json");
    this.isInitialized = false;
    this.runningProcesses = new Map();
    this.systemMetrics = {
      cpu: 0,
      memory: 0,
      disk: 0,
      temperature: 0,
      gpu: null,
    };

    this.availableModels = [
      {
        id: "gpt4all-falcon",
        name: "GPT4All Falcon 7B",
        description: "Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ù‚ÙˆÙŠ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©",
        size: 3800000000, // 3.8 GB
        downloadUrl:
          "https://gpt4all.io/models/ggml-model-gpt4all-falcon-q4_0.bin",
        executable: "gpt4all-falcon",
        type: "llm",
        status: "not-downloaded",
      },
      {
        id: "mistral-7b",
        name: "Mistral 7B Instruct",
        description: "Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠ",
        size: 4100000000, // 4.1 GB
        downloadUrl:
          "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/main/pytorch_model.bin",
        executable: "mistral-7b",
        type: "llm",
        status: "not-downloaded",
      },
      {
        id: "whisper-large",
        name: "Whisper Large V3",
        description: "ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©",
        size: 1500000000, // 1.5 GB
        downloadUrl:
          "https://openaipublic.azureedge.net/main/whisper/models/large-v3.pt",
        executable: "whisper",
        type: "audio",
        status: "not-downloaded",
      },
    ];

    this.init();
  }

  async init() {
    try {
      console.log("ğŸ¤– ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ...");

      // Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
      await this.ensureDirectories();

      // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
      await this.loadConfig();

      // ÙØ­Øµ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
      await this.scanAvailableModels();

      // Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
      this.startSystemMonitoring();

      // ØªØ³Ø¬ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬Ø§Øª IPC
      this.setupIPCHandlers();

      this.isInitialized = true;
      console.log("âœ… Ù…Ø¯ÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¬Ø§Ù‡Ø²!");
    } catch (error) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:", error);
    }
  }

  async ensureDirectories() {
    try {
      await fs.mkdir(this.modelsPath, { recursive: true });
      await fs.mkdir(path.join(this.modelsPath, "cache"), { recursive: true });
      await fs.mkdir(path.join(this.modelsPath, "logs"), { recursive: true });
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª:", error);
    }
  }

  async loadConfig() {
    try {
      const configData = await fs.readFile(this.configPath, "utf8");
      this.config = JSON.parse(configData);
    } catch (error) {
      // Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
      this.config = {
        aiEnabled: true,
        maxConcurrentModels: 2,
        maxMemoryUsage: 8192, // MB
        autoDownloadModels: false,
        language: "ar",
        systemMonitoring: true,
        lastUpdated: Date.now(),
      };
      await this.saveConfig();
    }
  }

  async saveConfig() {
    try {
      await fs.writeFile(this.configPath, JSON.stringify(this.config, null, 2));
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª:", error);
    }
  }

  async scanAvailableModels() {
    for (const model of this.availableModels) {
      const modelPath = path.join(this.modelsPath, model.id);
      try {
        await fs.access(modelPath);
        model.status = "downloaded";
        console.log(`âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model.name} Ù…ÙˆØ¬ÙˆØ¯`);
      } catch {
        model.status = "not-downloaded";
      }
    }
  }

  async downloadModel(modelId, onProgress) {
    const model = this.availableModels.find((m) => m.id === modelId);
    if (!model) throw new Error("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯");

    const modelPath = path.join(this.modelsPath, model.id);
    model.status = "downloading";

    try {
      console.log(`ğŸ“¥ Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ ${model.name}...`);

      // Ù…Ø­Ø§ÙƒØ§Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
      // ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙƒØªØ¨Ø© Ù…Ø«Ù„ axios Ø£Ùˆ node-fetch
      for (let progress = 0; progress <= 100; progress += 5) {
        await new Promise((resolve) => setTimeout(resolve, 200));
        if (onProgress) onProgress(progress);
        this.emit("download-progress", { modelId, progress });
      }

      // Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
      await fs.writeFile(
        modelPath,
        `# Knoux AI Model: ${model.name}\n# Size: ${model.size} bytes\n# Downloaded: ${new Date().toISOString()}\n`,
      );

      model.status = "downloaded";
      console.log(`âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ${model.name} Ø¨Ù†Ø¬Ø§Ø­`);
      this.emit("model-downloaded", model);
    } catch (error) {
      model.status = "error";
      console.error(`âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ ${model.name}:`, error);
      throw error;
    }
  }

  async startModel(modelId) {
    const model = this.availableModels.find((m) => m.id === modelId);
    if (!model || model.status !== "downloaded") {
      throw new Error("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ØªØ§Ø­");
    }

    if (this.runningProcesses.has(modelId)) {
      console.log(`Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model.name} ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„`);
      return;
    }

    try {
      console.log(`ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model.name}...`);

      // Ù…Ø­Ø§ÙƒØ§Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
      const mockProcess = {
        pid: Math.floor(Math.random() * 10000),
        model: model,
        startTime: Date.now(),
        status: "running",
        memoryUsage: model.size / 1000000, // ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ MB
        requestCount: 0,
      };

      this.runningProcesses.set(modelId, mockProcess);

      console.log(
        `âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model.name} ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† (PID: ${mockProcess.pid})`,
      );
      this.emit("model-started", model);
    } catch (error) {
      console.error(`âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model.name}:`, error);
      throw error;
    }
  }

  async stopModel(modelId) {
    const process = this.runningProcesses.get(modelId);
    if (!process) {
      throw new Error("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± ÙŠØ¹Ù…Ù„");
    }

    try {
      console.log(`ğŸ›‘ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${process.model.name}...`);

      this.runningProcesses.delete(modelId);

      console.log(`âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${process.model.name}`);
      this.emit("model-stopped", process.model);
    } catch (error) {
      console.error(`âŒ ÙØ´Ù„ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:`, error);
      throw error;
    }
  }

  async processRequest(modelId, requestData) {
    const process = this.runningProcesses.get(modelId);
    if (!process) {
      await this.startModel(modelId);
    }

    const runningProcess = this.runningProcesses.get(modelId);
    if (!runningProcess) {
      throw new Error("ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬");
    }

    try {
      runningProcess.requestCount++;

      // Ù…Ø­Ø§ÙƒØ§Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨
      const processingTime = Math.random() * 3000 + 1000; // 1-4 Ø«Ø§Ù†ÙŠØ©
      await new Promise((resolve) => setTimeout(resolve, processingTime));

      // Ø¥Ù†ØªØ§Ø¬ Ù†ØªÙŠØ¬Ø© ÙˆÙ‡Ù…ÙŠØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
      let result;
      const model = runningProcess.model;

      switch (model.type) {
        case "llm":
          result = this.generateTextResponse(requestData.prompt);
          break;
        case "audio":
          result = this.transcribeAudio(requestData.audioData);
          break;
        default:
          result = { text: "Ù†ØªÙŠØ¬Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠ", confidence: 0.9 };
      }

      console.log(
        `âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨ Ø¨ÙˆØ§Ø³Ø·Ø© ${model.name} ÙÙŠ ${processingTime}ms`,
      );

      return {
        success: true,
        data: result,
        processingTime,
        model: model.name,
        timestamp: Date.now(),
      };
    } catch (error) {
      console.error("âŒ ÙØ´Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨:", error);
      throw error;
    }
  }

  generateTextResponse(prompt) {
    const responses = [
      `Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„. ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„Ø¥Ù†ØªØ±Ù†Øª.

Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ: "${prompt}"

ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ:
â€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
â€¢ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆØªÙ„Ø®ÙŠØµÙ‡Ø§
â€¢ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª
â€¢ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©
â€¢ Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©

Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ÙŠÙ†ØŸ`,

      `Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙŠØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ. 

Ù„Ù‚Ø¯ ØªÙ„Ù‚ÙŠØª Ø³Ø¤Ø§Ù„Ùƒ: "${prompt}"

ÙˆØ£Ù‚Ø¯Ø± Ù„Ùƒ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ©. ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ Ù…Ø®ØªÙ„Ù Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø¹ Ø¶Ù…Ø§Ù† Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª ØªØªÙ… Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ.

Ù…Ø§ Ø±Ø£ÙŠÙƒ Ø£Ù† Ù†ØªØ¹Ù…Ù‚ Ø£ÙƒØ«Ø± ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŸ`,
    ];

    return {
      text: responses[Math.floor(Math.random() * responses.length)],
      confidence: 0.85 + Math.random() * 0.14,
      tokens: 150 + Math.floor(Math.random() * 100),
    };
  }

  transcribeAudio(audioData) {
    const transcriptions = [
      "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Whisper Ø§Ù„Ù…Ø­Ù„ÙŠ. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£ØµÙˆØ§Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©.",
      "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ Knoux SmartOrganizer Ø§Ù„Ø°ÙƒÙŠ. Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠÙˆÙØ± Ø£Ø¯ÙˆØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.",
      "ØªÙ‚Ù†ÙŠØ© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ ØªØ¹Ù…Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø®ÙˆØ§Ø¯Ù… Ø®Ø§Ø±Ø¬ÙŠØ©ØŒ Ù…Ù…Ø§ ÙŠØ¶Ù…Ù† Ø®ØµÙˆØµÙŠØ© ÙˆØ£Ù…Ø§Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙƒ.",
    ];

    const text =
      transcriptions[Math.floor(Math.random() * transcriptions.length)];

    return {
      text,
      language: "ar",
      confidence: 0.88 + Math.random() * 0.11,
      duration: 15 + Math.random() * 30,
      segments: text
        .split(".")
        .map((segment, index) => ({
          start: index * 5,
          end: (index + 1) * 5,
          text: segment.trim(),
        }))
        .filter((s) => s.text.length > 0),
    };
  }

  startSystemMonitoring() {
    setInterval(() => {
      this.updateSystemMetrics();
    }, 2000);
  }

  async updateSystemMetrics() {
    try {
      // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
      const cpuUsage = await this.getCPUUsage();
      const memoryInfo = process.memoryUsage();
      const systemInfo = {
        platform: os.platform(),
        arch: os.arch(),
        cpus: os.cpus().length,
        totalMemory: os.totalmem(),
        freeMemory: os.freemem(),
      };

      this.systemMetrics = {
        timestamp: Date.now(),
        cpu: {
          usage: cpuUsage,
          cores: systemInfo.cpus,
          temperature: 45 + Math.random() * 30, // Ù…Ø­Ø§ÙƒØ§Ø© Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©
        },
        memory: {
          total: systemInfo.totalMemory,
          free: systemInfo.freeMemory,
          used: systemInfo.totalMemory - systemInfo.freeMemory,
          percentage:
            ((systemInfo.totalMemory - systemInfo.freeMemory) /
              systemInfo.totalMemory) *
            100,
        },
        processes: Array.from(this.runningProcesses.values()).map(
          (process) => ({
            pid: process.pid,
            name: process.model.name,
            memoryUsage: process.memoryUsage,
            requestCount: process.requestCount,
            uptime: Date.now() - process.startTime,
          }),
        ),
        models: this.availableModels.map((model) => ({
          id: model.id,
          name: model.name,
          status: model.status,
          isRunning: this.runningProcesses.has(model.id),
        })),
      };

      this.emit("system-metrics", this.systemMetrics);
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ø¸Ø§Ù…:", error);
    }
  }

  async getCPUUsage() {
    return new Promise((resolve) => {
      const startUsage = process.cpuUsage();
      setTimeout(() => {
        const endUsage = process.cpuUsage(startUsage);
        const totalUsage = endUsage.user + endUsage.system;
        const percentage = (totalUsage / 10000000) * 100; // ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
        resolve(Math.min(percentage, 100));
      }, 100);
    });
  }

  setupIPCHandlers() {
    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    ipcMain.handle("ai:get-models", () => {
      return this.availableModels;
    });

    // ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬
    ipcMain.handle("ai:download-model", async (event, modelId) => {
      return this.downloadModel(modelId, (progress) => {
        event.sender.send("ai:download-progress", { modelId, progress });
      });
    });

    // ØªØ´ØºÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬
    ipcMain.handle("ai:start-model", (event, modelId) => {
      return this.startModel(modelId);
    });

    // Ø¥ÙŠÙ‚Ø§Ù Ù†Ù…ÙˆØ°Ø¬
    ipcMain.handle("ai:stop-model", (event, modelId) => {
      return this.stopModel(modelId);
    });

    // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨
    ipcMain.handle("ai:process-request", (event, modelId, requestData) => {
      return this.processRequest(modelId, requestData);
    });

    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ø¸Ø§Ù…
    ipcMain.handle("ai:get-system-metrics", () => {
      return this.systemMetrics;
    });

    // Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    ipcMain.handle("ai:get-config", () => {
      return this.config;
    });

    // ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    ipcMain.handle("ai:update-config", async (event, newConfig) => {
      this.config = { ...this.config, ...newConfig };
      await this.saveConfig();
      return this.config;
    });

    // ÙØªØ­ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    ipcMain.handle("ai:open-models-folder", () => {
      shell.openPath(this.modelsPath);
    });

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    ipcMain.handle("ai:cleanup-cache", async () => {
      const cachePath = path.join(this.modelsPath, "cache");
      try {
        const files = await fs.readdir(cachePath);
        for (const file of files) {
          await fs.unlink(path.join(cachePath, file));
        }
        return { success: true, message: "ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©" };
      } catch (error) {
        return { success: false, error: error.message };
      }
    });
  }

  getStatus() {
    return {
      initialized: this.isInitialized,
      modelsPath: this.modelsPath,
      availableModels: this.availableModels.length,
      runningModels: this.runningProcesses.size,
      systemMetrics: this.systemMetrics,
      config: this.config,
    };
  }

  destroy() {
    // Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    for (const modelId of this.runningProcesses.keys()) {
      this.stopModel(modelId).catch(console.error);
    }

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
    this.removeAllListeners();
    this.isInitialized = false;
  }
}

module.exports = OfflineAIManager;
